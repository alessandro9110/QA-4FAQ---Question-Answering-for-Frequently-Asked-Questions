{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import certifi\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD TOKENIZER FILES\n",
    "def loadSentences(filename):\n",
    "    array = []\n",
    "    with open(filename) as f:\n",
    "        ar = []\n",
    "        for line in f:\n",
    "            if (str(line) != \"[\\n\") & (str(line) != \"]\\n\"):\n",
    "                ar.append(re.sub('\\n$', '', line))\n",
    "                #print (line)\n",
    "            if (str(line) == \"]\\n\"):\n",
    "                array.append(ar)\n",
    "                ar = []\n",
    "            \n",
    "    f.close()\n",
    "    return array\n",
    "\n",
    "#le 406 domande\n",
    "Question = loadSentences(\"tokenizer/tokenizerQuestion.txt\")\n",
    "\n",
    "#le 406 risposte\n",
    "Answer = loadSentences(\"tokenizer/tokenizerAnswer.txt\")\n",
    "\n",
    "#le 1000 ecc per calcolare lo score\n",
    "QTest = loadSentences(\"tokenizer/tokenizerQTest.txt\")\n",
    "\n",
    "# le 3 domande di test\n",
    "Test = loadSentences(\"tokenizer/tokenizerTest.txt\")\n",
    "\n",
    "#question + answer\n",
    "QA = loadSentences(\"tokenizer/tokenizerQuestionAnswer.txt\")\n",
    "\n",
    "#mettiamo tutto insieme per avere un unico vocabolario\n",
    "full=Question + Answer + Test + QTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENSIM W2V Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word to Vect\n",
    "# import modules & set up logging\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "# train word2vec \n",
    "iterN = 10 #how many times the training code will run through the data set to train \n",
    "#the neural network (kind of like the number of training epochs).\n",
    "\n",
    "mc = 1 #specifies the minimum amount of times that the word has to appear in the corpus \n",
    "#before it is included in the vocabulary – this allows us to easily eliminate rare words \n",
    "#and reduce our vocabulary size\n",
    "\n",
    "s = 50 #In other words, each word in our vocabulary, after training, will be represented \n",
    "#by a 200 length word vector.\n",
    "\n",
    "job = 4 #parallel workers we would like to work on the data – this will speed up the training process\n",
    "window = 5 #contorno di 5 parole (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-13 09:34:15,417 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-03-13 09:34:15,418 : INFO : collecting all words and their counts\n",
      "2018-03-13 09:34:15,420 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-13 09:34:15,423 : INFO : collected 995 word types from a corpus of 4267 raw words and 406 sentences\n",
      "2018-03-13 09:34:15,424 : INFO : Loading a fresh vocabulary\n",
      "2018-03-13 09:34:15,430 : INFO : min_count=1 retains 995 unique words (100% of original 995, drops 0)\n",
      "2018-03-13 09:34:15,431 : INFO : min_count=1 leaves 4267 word corpus (100% of original 4267, drops 0)\n",
      "2018-03-13 09:34:15,437 : INFO : deleting the raw counts dictionary of 995 items\n",
      "2018-03-13 09:34:15,438 : INFO : sample=0.001 downsamples 73 most-common words\n",
      "2018-03-13 09:34:15,439 : INFO : downsampling leaves estimated 3043 word corpus (71.3% of prior 4267)\n",
      "2018-03-13 09:34:15,444 : INFO : estimated required memory for 995 words and 50 dimensions: 895500 bytes\n",
      "2018-03-13 09:34:15,445 : INFO : resetting layer weights\n",
      "2018-03-13 09:34:15,462 : INFO : training model with 3 workers on 995 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-13 09:34:15,466 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,470 : INFO : EPOCH - 1 : training on 4267 raw words (3035 effective words) took 0.0s, 690797 effective words/s\n",
      "2018-03-13 09:34:15,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,479 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,479 : INFO : EPOCH - 2 : training on 4267 raw words (3063 effective words) took 0.0s, 492447 effective words/s\n",
      "2018-03-13 09:34:15,482 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,486 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,486 : INFO : EPOCH - 3 : training on 4267 raw words (3050 effective words) took 0.0s, 564589 effective words/s\n",
      "2018-03-13 09:34:15,489 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,490 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,495 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,495 : INFO : EPOCH - 4 : training on 4267 raw words (3041 effective words) took 0.0s, 508962 effective words/s\n",
      "2018-03-13 09:34:15,498 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,499 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,502 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,503 : INFO : EPOCH - 5 : training on 4267 raw words (3055 effective words) took 0.0s, 507377 effective words/s\n",
      "2018-03-13 09:34:15,506 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,507 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,512 : INFO : EPOCH - 6 : training on 4267 raw words (3075 effective words) took 0.0s, 570383 effective words/s\n",
      "2018-03-13 09:34:15,515 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,516 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,519 : INFO : EPOCH - 7 : training on 4267 raw words (3044 effective words) took 0.0s, 540246 effective words/s\n",
      "2018-03-13 09:34:15,522 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,525 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,526 : INFO : EPOCH - 8 : training on 4267 raw words (3041 effective words) took 0.0s, 574472 effective words/s\n",
      "2018-03-13 09:34:15,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,530 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,533 : INFO : EPOCH - 9 : training on 4267 raw words (3089 effective words) took 0.0s, 581371 effective words/s\n",
      "2018-03-13 09:34:15,536 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,537 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,540 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,540 : INFO : EPOCH - 10 : training on 4267 raw words (3067 effective words) took 0.0s, 523181 effective words/s\n",
      "2018-03-13 09:34:15,541 : INFO : training on a 42670 raw words (30560 effective words) took 0.1s, 387793 effective words/s\n",
      "2018-03-13 09:34:15,542 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2018-03-13 09:34:15,543 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-03-13 09:34:15,543 : INFO : collecting all words and their counts\n",
      "2018-03-13 09:34:15,544 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-13 09:34:15,558 : INFO : collected 4131 word types from a corpus of 36170 raw words and 406 sentences\n",
      "2018-03-13 09:34:15,559 : INFO : Loading a fresh vocabulary\n",
      "2018-03-13 09:34:15,576 : INFO : min_count=1 retains 4131 unique words (100% of original 4131, drops 0)\n",
      "2018-03-13 09:34:15,577 : INFO : min_count=1 leaves 36170 word corpus (100% of original 36170, drops 0)\n",
      "2018-03-13 09:34:15,595 : INFO : deleting the raw counts dictionary of 4131 items\n",
      "2018-03-13 09:34:15,596 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2018-03-13 09:34:15,596 : INFO : downsampling leaves estimated 27710 word corpus (76.6% of prior 36170)\n",
      "2018-03-13 09:34:15,610 : INFO : estimated required memory for 4131 words and 50 dimensions: 3717900 bytes\n",
      "2018-03-13 09:34:15,611 : INFO : resetting layer weights\n",
      "2018-03-13 09:34:15,677 : INFO : training model with 3 workers on 4131 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-13 09:34:15,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,727 : INFO : EPOCH - 1 : training on 36170 raw words (27670 effective words) took 0.0s, 573005 effective words/s\n",
      "2018-03-13 09:34:15,757 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,758 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,767 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,768 : INFO : EPOCH - 2 : training on 36170 raw words (27754 effective words) took 0.0s, 713321 effective words/s\n",
      "2018-03-13 09:34:15,792 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,799 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,799 : INFO : EPOCH - 3 : training on 36170 raw words (27694 effective words) took 0.0s, 959726 effective words/s\n",
      "2018-03-13 09:34:15,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,828 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-13 09:34:15,828 : INFO : EPOCH - 4 : training on 36170 raw words (27698 effective words) took 0.0s, 1031386 effective words/s\n",
      "2018-03-13 09:34:15,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,851 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,853 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,854 : INFO : EPOCH - 5 : training on 36170 raw words (27802 effective words) took 0.0s, 1181268 effective words/s\n",
      "2018-03-13 09:34:15,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,880 : INFO : EPOCH - 6 : training on 36170 raw words (27795 effective words) took 0.0s, 1157551 effective words/s\n",
      "2018-03-13 09:34:15,900 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,903 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,906 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,907 : INFO : EPOCH - 7 : training on 36170 raw words (27712 effective words) took 0.0s, 1110317 effective words/s\n",
      "2018-03-13 09:34:15,927 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,934 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,947 : INFO : EPOCH - 8 : training on 36170 raw words (27713 effective words) took 0.0s, 755991 effective words/s\n",
      "2018-03-13 09:34:15,966 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:15,974 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:15,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:15,981 : INFO : EPOCH - 9 : training on 36170 raw words (27723 effective words) took 0.0s, 872184 effective words/s\n",
      "2018-03-13 09:34:16,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,007 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,011 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,012 : INFO : EPOCH - 10 : training on 36170 raw words (27594 effective words) took 0.0s, 956789 effective words/s\n",
      "2018-03-13 09:34:16,014 : INFO : training on a 361700 raw words (277155 effective words) took 0.3s, 824623 effective words/s\n",
      "2018-03-13 09:34:16,017 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-03-13 09:34:16,018 : INFO : collecting all words and their counts\n",
      "2018-03-13 09:34:16,019 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-13 09:34:16,038 : INFO : collected 4338 word types from a corpus of 40437 raw words and 406 sentences\n",
      "2018-03-13 09:34:16,039 : INFO : Loading a fresh vocabulary\n",
      "2018-03-13 09:34:16,159 : INFO : min_count=1 retains 4338 unique words (100% of original 4338, drops 0)\n",
      "2018-03-13 09:34:16,160 : INFO : min_count=1 leaves 40437 word corpus (100% of original 40437, drops 0)\n",
      "2018-03-13 09:34:16,173 : INFO : deleting the raw counts dictionary of 4338 items\n",
      "2018-03-13 09:34:16,174 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2018-03-13 09:34:16,175 : INFO : downsampling leaves estimated 31112 word corpus (76.9% of prior 40437)\n",
      "2018-03-13 09:34:16,186 : INFO : estimated required memory for 4338 words and 50 dimensions: 3904200 bytes\n",
      "2018-03-13 09:34:16,187 : INFO : resetting layer weights\n",
      "2018-03-13 09:34:16,245 : INFO : training model with 3 workers on 4338 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-13 09:34:16,278 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,284 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,285 : INFO : EPOCH - 1 : training on 40437 raw words (31170 effective words) took 0.0s, 831373 effective words/s\n",
      "2018-03-13 09:34:16,317 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,319 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,320 : INFO : EPOCH - 2 : training on 40437 raw words (31101 effective words) took 0.0s, 938205 effective words/s\n",
      "2018-03-13 09:34:16,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,352 : INFO : EPOCH - 3 : training on 40437 raw words (31185 effective words) took 0.0s, 1044903 effective words/s\n",
      "2018-03-13 09:34:16,380 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,391 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,394 : INFO : EPOCH - 4 : training on 40437 raw words (30989 effective words) took 0.0s, 795749 effective words/s\n",
      "2018-03-13 09:34:16,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,417 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,424 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,425 : INFO : EPOCH - 5 : training on 40437 raw words (31008 effective words) took 0.0s, 1076116 effective words/s\n",
      "2018-03-13 09:34:16,448 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,449 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,456 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,457 : INFO : EPOCH - 6 : training on 40437 raw words (31138 effective words) took 0.0s, 1075517 effective words/s\n",
      "2018-03-13 09:34:16,480 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,481 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,488 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,489 : INFO : EPOCH - 7 : training on 40437 raw words (31229 effective words) took 0.0s, 1063654 effective words/s\n",
      "2018-03-13 09:34:16,512 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,513 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,520 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,521 : INFO : EPOCH - 8 : training on 40437 raw words (31184 effective words) took 0.0s, 1067216 effective words/s\n",
      "2018-03-13 09:34:16,544 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,554 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,558 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,559 : INFO : EPOCH - 9 : training on 40437 raw words (31183 effective words) took 0.0s, 885554 effective words/s\n",
      "2018-03-13 09:34:16,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,595 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,595 : INFO : EPOCH - 10 : training on 40437 raw words (31091 effective words) took 0.0s, 909297 effective words/s\n",
      "2018-03-13 09:34:16,596 : INFO : training on a 404370 raw words (311278 effective words) took 0.4s, 887750 effective words/s\n",
      "2018-03-13 09:34:16,600 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-13 09:34:16,601 : INFO : collecting all words and their counts\n",
      "2018-03-13 09:34:16,602 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-13 09:34:16,607 : INFO : collected 1505 word types from a corpus of 8958 raw words and 1132 sentences\n",
      "2018-03-13 09:34:16,608 : INFO : Loading a fresh vocabulary\n",
      "2018-03-13 09:34:16,617 : INFO : min_count=1 retains 1505 unique words (100% of original 1505, drops 0)\n",
      "2018-03-13 09:34:16,619 : INFO : min_count=1 leaves 8958 word corpus (100% of original 8958, drops 0)\n",
      "2018-03-13 09:34:16,628 : INFO : deleting the raw counts dictionary of 1505 items\n",
      "2018-03-13 09:34:16,629 : INFO : sample=0.001 downsamples 69 most-common words\n",
      "2018-03-13 09:34:16,630 : INFO : downsampling leaves estimated 6159 word corpus (68.8% of prior 8958)\n",
      "2018-03-13 09:34:16,637 : INFO : estimated required memory for 1505 words and 50 dimensions: 1354500 bytes\n",
      "2018-03-13 09:34:16,638 : INFO : resetting layer weights\n",
      "2018-03-13 09:34:16,669 : INFO : training model with 3 workers on 1505 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-13 09:34:16,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,691 : INFO : EPOCH - 1 : training on 8958 raw words (6153 effective words) took 0.0s, 323408 effective words/s\n",
      "2018-03-13 09:34:16,696 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,697 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,704 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,705 : INFO : EPOCH - 2 : training on 8958 raw words (6170 effective words) took 0.0s, 551277 effective words/s\n",
      "2018-03-13 09:34:16,710 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,711 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,718 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,719 : INFO : EPOCH - 3 : training on 8958 raw words (6166 effective words) took 0.0s, 547278 effective words/s\n",
      "2018-03-13 09:34:16,725 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,726 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,733 : INFO : EPOCH - 4 : training on 8958 raw words (6181 effective words) took 0.0s, 750252 effective words/s\n",
      "2018-03-13 09:34:16,738 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,739 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,746 : INFO : EPOCH - 5 : training on 8958 raw words (6189 effective words) took 0.0s, 571758 effective words/s\n",
      "2018-03-13 09:34:16,751 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,753 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,760 : INFO : EPOCH - 6 : training on 8958 raw words (6095 effective words) took 0.0s, 571122 effective words/s\n",
      "2018-03-13 09:34:16,765 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,773 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,774 : INFO : EPOCH - 7 : training on 8958 raw words (6130 effective words) took 0.0s, 568202 effective words/s\n",
      "2018-03-13 09:34:16,778 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,787 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,787 : INFO : EPOCH - 8 : training on 8958 raw words (6147 effective words) took 0.0s, 556850 effective words/s\n",
      "2018-03-13 09:34:16,792 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,802 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,803 : INFO : EPOCH - 9 : training on 8958 raw words (6102 effective words) took 0.0s, 477364 effective words/s\n",
      "2018-03-13 09:34:16,808 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,817 : INFO : EPOCH - 10 : training on 8958 raw words (6125 effective words) took 0.0s, 695458 effective words/s\n",
      "2018-03-13 09:34:16,818 : INFO : training on a 89580 raw words (61458 effective words) took 0.1s, 414697 effective words/s\n",
      "2018-03-13 09:34:16,818 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2018-03-13 09:34:16,820 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-03-13 09:34:16,820 : INFO : collecting all words and their counts\n",
      "2018-03-13 09:34:16,826 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-13 09:34:16,828 : INFO : collected 15 word types from a corpus of 16 raw words and 3 sentences\n",
      "2018-03-13 09:34:16,830 : INFO : Loading a fresh vocabulary\n",
      "2018-03-13 09:34:16,832 : INFO : min_count=1 retains 15 unique words (100% of original 15, drops 0)\n",
      "2018-03-13 09:34:16,832 : INFO : min_count=1 leaves 16 word corpus (100% of original 16, drops 0)\n",
      "2018-03-13 09:34:16,834 : INFO : deleting the raw counts dictionary of 15 items\n",
      "2018-03-13 09:34:16,834 : INFO : sample=0.001 downsamples 15 most-common words\n",
      "2018-03-13 09:34:16,835 : INFO : downsampling leaves estimated 2 word corpus (13.7% of prior 16)\n",
      "2018-03-13 09:34:16,836 : INFO : estimated required memory for 15 words and 50 dimensions: 13500 bytes\n",
      "2018-03-13 09:34:16,838 : INFO : resetting layer weights\n",
      "2018-03-13 09:34:16,840 : INFO : training model with 3 workers on 15 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-13 09:34:16,842 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,843 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,844 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,845 : INFO : EPOCH - 1 : training on 16 raw words (2 effective words) took 0.0s, 683 effective words/s\n",
      "2018-03-13 09:34:16,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,849 : INFO : EPOCH - 2 : training on 16 raw words (3 effective words) took 0.0s, 1046 effective words/s\n",
      "2018-03-13 09:34:16,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,855 : INFO : EPOCH - 3 : training on 16 raw words (1 effective words) took 0.0s, 326 effective words/s\n",
      "2018-03-13 09:34:16,857 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,859 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,861 : INFO : EPOCH - 4 : training on 16 raw words (2 effective words) took 0.0s, 511 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-13 09:34:16,863 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,867 : INFO : EPOCH - 5 : training on 16 raw words (1 effective words) took 0.0s, 309 effective words/s\n",
      "2018-03-13 09:34:16,869 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,870 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,872 : INFO : EPOCH - 6 : training on 16 raw words (4 effective words) took 0.0s, 1193 effective words/s\n",
      "2018-03-13 09:34:16,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,875 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,877 : INFO : EPOCH - 7 : training on 16 raw words (1 effective words) took 0.0s, 297 effective words/s\n",
      "2018-03-13 09:34:16,880 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,880 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,881 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,882 : INFO : EPOCH - 8 : training on 16 raw words (1 effective words) took 0.0s, 315 effective words/s\n",
      "2018-03-13 09:34:16,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,887 : INFO : EPOCH - 9 : training on 16 raw words (3 effective words) took 0.0s, 973 effective words/s\n",
      "2018-03-13 09:34:16,889 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:16,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:16,892 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:16,892 : INFO : EPOCH - 10 : training on 16 raw words (2 effective words) took 0.0s, 621 effective words/s\n",
      "2018-03-13 09:34:16,893 : INFO : training on a 160 raw words (20 effective words) took 0.1s, 380 effective words/s\n",
      "2018-03-13 09:34:16,894 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2018-03-13 09:34:16,895 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-03-13 09:34:16,896 : INFO : collecting all words and their counts\n",
      "2018-03-13 09:34:16,897 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-13 09:34:16,910 : INFO : collected 4898 word types from a corpus of 49411 raw words and 1947 sentences\n",
      "2018-03-13 09:34:16,911 : INFO : Loading a fresh vocabulary\n",
      "2018-03-13 09:34:16,923 : INFO : min_count=1 retains 4898 unique words (100% of original 4898, drops 0)\n",
      "2018-03-13 09:34:16,924 : INFO : min_count=1 leaves 49411 word corpus (100% of original 49411, drops 0)\n",
      "2018-03-13 09:34:16,937 : INFO : deleting the raw counts dictionary of 4898 items\n",
      "2018-03-13 09:34:16,938 : INFO : sample=0.001 downsamples 53 most-common words\n",
      "2018-03-13 09:34:16,939 : INFO : downsampling leaves estimated 38128 word corpus (77.2% of prior 49411)\n",
      "2018-03-13 09:34:16,950 : INFO : estimated required memory for 4898 words and 50 dimensions: 4408200 bytes\n",
      "2018-03-13 09:34:16,951 : INFO : resetting layer weights\n",
      "2018-03-13 09:34:17,013 : INFO : training model with 3 workers on 4898 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-13 09:34:17,064 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,072 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,074 : INFO : EPOCH - 1 : training on 49411 raw words (38174 effective words) took 0.1s, 697020 effective words/s\n",
      "2018-03-13 09:34:17,110 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,117 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,122 : INFO : EPOCH - 2 : training on 49411 raw words (38083 effective words) took 0.0s, 905383 effective words/s\n",
      "2018-03-13 09:34:17,155 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,165 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,169 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,170 : INFO : EPOCH - 3 : training on 49411 raw words (38208 effective words) took 0.0s, 901870 effective words/s\n",
      "2018-03-13 09:34:17,207 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,220 : INFO : EPOCH - 4 : training on 49411 raw words (38146 effective words) took 0.0s, 875069 effective words/s\n",
      "2018-03-13 09:34:17,261 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,262 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,268 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,269 : INFO : EPOCH - 5 : training on 49411 raw words (38050 effective words) took 0.0s, 830341 effective words/s\n",
      "2018-03-13 09:34:17,302 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,306 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,317 : INFO : EPOCH - 6 : training on 49411 raw words (38166 effective words) took 0.0s, 872866 effective words/s\n",
      "2018-03-13 09:34:17,352 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,360 : INFO : EPOCH - 7 : training on 49411 raw words (38163 effective words) took 0.0s, 1022068 effective words/s\n",
      "2018-03-13 09:34:17,390 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,393 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,401 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,402 : INFO : EPOCH - 8 : training on 49411 raw words (38038 effective words) took 0.0s, 1007088 effective words/s\n",
      "2018-03-13 09:34:17,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,436 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,437 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,438 : INFO : EPOCH - 9 : training on 49411 raw words (38080 effective words) took 0.0s, 1198962 effective words/s\n",
      "2018-03-13 09:34:17,472 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-13 09:34:17,478 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-13 09:34:17,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-13 09:34:17,483 : INFO : EPOCH - 10 : training on 49411 raw words (38208 effective words) took 0.0s, 938002 effective words/s\n",
      "2018-03-13 09:34:17,485 : INFO : training on a 494110 raw words (381316 effective words) took 0.5s, 809722 effective words/s\n"
     ]
    }
   ],
   "source": [
    "#Question\n",
    "modelQ = gensim.models.Word2Vec(Question, iter = iterN, min_count=mc, size = s)\n",
    "\n",
    "#Answer\n",
    "modelA = gensim.models.Word2Vec(Answer, iter = iterN, min_count=mc, size = s)\n",
    "\n",
    "#Question+Answer\n",
    "modelQA = gensim.models.Word2Vec(QA, iter = iterN, min_count=mc, size = s)\n",
    "\n",
    "#Qtest\n",
    "modelQTest = gensim.models.Word2Vec(QTest, iter = iterN, min_count=mc, size = s)\n",
    "\n",
    "#test\n",
    "modelTest = gensim.models.Word2Vec(Test, iter = iterN, min_count=mc, size = s)\n",
    "\n",
    "#model full, ossia il modello gensim con Q+A+Qtest+test per creare un unico vocabolario\n",
    "modelFull = gensim.models.Word2Vec(full, iter = iterN, min_count=mc, size = s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-13 09:34:34,677 : INFO : saving Word2Vec object under model/vector_50/mymodelQ, separately None\n",
      "2018-03-13 09:34:34,679 : INFO : not storing attribute vectors_norm\n",
      "2018-03-13 09:34:34,680 : INFO : not storing attribute cum_table\n",
      "2018-03-13 09:34:34,696 : INFO : saved model/vector_50/mymodelQ\n",
      "2018-03-13 09:34:34,697 : INFO : saving Word2Vec object under model/vector_50/mymodelA, separately None\n",
      "2018-03-13 09:34:34,698 : INFO : not storing attribute vectors_norm\n",
      "2018-03-13 09:34:34,699 : INFO : not storing attribute cum_table\n",
      "2018-03-13 09:34:34,742 : INFO : saved model/vector_50/mymodelA\n",
      "2018-03-13 09:34:34,743 : INFO : saving Word2Vec object under model/vector_50/mymodelQA, separately None\n",
      "2018-03-13 09:34:34,744 : INFO : not storing attribute vectors_norm\n",
      "2018-03-13 09:34:34,744 : INFO : not storing attribute cum_table\n",
      "2018-03-13 09:34:34,779 : INFO : saved model/vector_50/mymodelQA\n",
      "2018-03-13 09:34:34,779 : INFO : saving Word2Vec object under model/vector_50/mymodelQTest, separately None\n",
      "2018-03-13 09:34:34,780 : INFO : not storing attribute vectors_norm\n",
      "2018-03-13 09:34:34,781 : INFO : not storing attribute cum_table\n",
      "2018-03-13 09:34:34,792 : INFO : saved model/vector_50/mymodelQTest\n",
      "2018-03-13 09:34:34,793 : INFO : saving Word2Vec object under model/vector_50/mymodelTest, separately None\n",
      "2018-03-13 09:34:34,795 : INFO : not storing attribute vectors_norm\n",
      "2018-03-13 09:34:34,796 : INFO : not storing attribute cum_table\n",
      "2018-03-13 09:34:34,797 : INFO : saved model/vector_50/mymodelTest\n",
      "2018-03-13 09:34:34,799 : INFO : saving Word2Vec object under model/vector_50/mymodelFull, separately None\n",
      "2018-03-13 09:34:34,800 : INFO : not storing attribute vectors_norm\n",
      "2018-03-13 09:34:34,801 : INFO : not storing attribute cum_table\n",
      "2018-03-13 09:34:34,828 : INFO : saved model/vector_50/mymodelFull\n"
     ]
    }
   ],
   "source": [
    "#salva modello\n",
    "modelQ.save('model/vector_50/mymodelQ')\n",
    "\n",
    "modelA.save('model/vector_50/mymodelA')\n",
    "\n",
    "modelQA.save('model/vector_50/mymodelQA')\n",
    "\n",
    "modelQTest.save('model/vector_50/mymodelQTest')\n",
    "\n",
    "modelTest.save('model/vector_50/mymodelTest')\n",
    "\n",
    "modelFull.save('model/vector_50/mymodelFull')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextProject",
   "language": "python",
   "name": "textproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
